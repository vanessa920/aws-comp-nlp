{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import engine,testinit,loadEngine,saveEngine\n",
    "from datetime import datetime\n",
    "from pathlib import WindowsPath,PosixPath\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Initialization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 18:35:01.219 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K--initializing LDA core--abulary--aframe content II--\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 18:36:12.937 INFO    gensim.models.word2vec: collecting all words and their counts\n",
      "2021-05-18 18:36:12.938 INFO    gensim.models.word2vec: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-05-18 18:36:12.961 INFO    gensim.models.word2vec: collected 7128 word types from a corpus of 158604 raw words and 1648 sentences\n",
      "2021-05-18 18:36:12.961 INFO    gensim.models.word2vec: Loading a fresh vocabulary\n",
      "2021-05-18 18:36:12.973 INFO    gensim.models.word2vec: effective_min_count=1 retains 7128 unique words (100% of original 7128, drops 0)\n",
      "2021-05-18 18:36:12.975 INFO    gensim.models.word2vec: effective_min_count=1 leaves 158604 word corpus (100% of original 158604, drops 0)\n",
      "2021-05-18 18:36:12.998 INFO    gensim.models.word2vec: deleting the raw counts dictionary of 7128 items\n",
      "2021-05-18 18:36:12.998 INFO    gensim.models.word2vec: sample=0.001 downsamples 57 most-common words\n",
      "2021-05-18 18:36:12.999 INFO    gensim.models.word2vec: downsampling leaves estimated 136210 word corpus (85.9% of prior 158604)\n",
      "2021-05-18 18:36:13.014 INFO    gensim.models.base_any2vec: estimated required memory for 7128 words and 100 dimensions: 9266400 bytes\n",
      "2021-05-18 18:36:13.014 INFO    gensim.models.word2vec: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K--initializing word to vector core--\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-18 18:36:14.155 INFO    gensim.models.base_any2vec: training model with 2 workers on 7128 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-05-18 18:36:14.514 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-18 18:36:14.517 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-18 18:36:14.517 INFO    gensim.models.base_any2vec: EPOCH - 1 : training on 158604 raw words (136165 effective words) took 0.4s, 381834 effective words/s\n",
      "2021-05-18 18:36:14.905 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-18 18:36:14.908 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-18 18:36:14.908 INFO    gensim.models.base_any2vec: EPOCH - 2 : training on 158604 raw words (136470 effective words) took 0.4s, 352511 effective words/s\n",
      "2021-05-18 18:36:15.286 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-18 18:36:15.287 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-18 18:36:15.287 INFO    gensim.models.base_any2vec: EPOCH - 3 : training on 158604 raw words (136360 effective words) took 0.4s, 365785 effective words/s\n",
      "2021-05-18 18:36:15.685 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-18 18:36:15.687 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-18 18:36:15.688 INFO    gensim.models.base_any2vec: EPOCH - 4 : training on 158604 raw words (136207 effective words) took 0.4s, 343281 effective words/s\n",
      "2021-05-18 18:36:16.096 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-18 18:36:16.100 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-18 18:36:16.100 INFO    gensim.models.base_any2vec: EPOCH - 5 : training on 158604 raw words (136252 effective words) took 0.4s, 334047 effective words/s\n",
      "2021-05-18 18:36:16.100 INFO    gensim.models.base_any2vec: training on a 793020 raw words (681454 effective words) took 1.9s, 350428 effective words/s\n"
     ]
    }
   ],
   "source": [
    "test_engine = engine()\n",
    "test_engine.loadCSV('city_SanJose_Minutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takes 0.81597900390625 second to save\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nlp_engine.pkl'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveEngine('nlp_engine.pkl',test_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sending pdf to tika to process ---\n",
      ".\\data\\Minutes_02.pdf\n",
      "--- file sent, waiting for results ---\n",
      "\u001b[K--clean and spacy transforming dataframe content II--\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 18:08:57.698 INFO    gensim.models.word2vec: collecting all words and their counts\n",
      "2021-05-17 18:08:57.698 INFO    gensim.models.word2vec: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-05-17 18:08:57.726 INFO    gensim.models.word2vec: collected 6998 word types from a corpus of 162653 raw words and 1692 sentences\n",
      "2021-05-17 18:08:57.726 INFO    gensim.models.word2vec: Loading a fresh vocabulary\n",
      "2021-05-17 18:08:57.735 INFO    gensim.models.word2vec: effective_min_count=1 retains 6998 unique words (100% of original 6998, drops 0)\n",
      "2021-05-17 18:08:57.736 INFO    gensim.models.word2vec: effective_min_count=1 leaves 162653 word corpus (100% of original 162653, drops 0)\n",
      "2021-05-17 18:08:57.751 INFO    gensim.models.word2vec: deleting the raw counts dictionary of 6998 items\n",
      "2021-05-17 18:08:57.752 INFO    gensim.models.word2vec: sample=0.001 downsamples 60 most-common words\n",
      "2021-05-17 18:08:57.752 INFO    gensim.models.word2vec: downsampling leaves estimated 139278 word corpus (85.6% of prior 162653)\n",
      "2021-05-17 18:08:57.765 INFO    gensim.models.base_any2vec: estimated required memory for 6998 words and 100 dimensions: 9097400 bytes\n",
      "2021-05-17 18:08:57.766 INFO    gensim.models.word2vec: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine retrain started\n",
      "TFIDF core training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-17 18:08:58.737 INFO    gensim.models.base_any2vec: training model with 2 workers on 6998 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-05-17 18:08:59.071 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-17 18:08:59.094 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-17 18:08:59.094 INFO    gensim.models.base_any2vec: EPOCH - 1 : training on 162653 raw words (139305 effective words) took 0.4s, 392682 effective words/s\n",
      "2021-05-17 18:08:59.426 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-17 18:08:59.465 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-17 18:08:59.466 INFO    gensim.models.base_any2vec: EPOCH - 2 : training on 162653 raw words (139321 effective words) took 0.4s, 377724 effective words/s\n",
      "2021-05-17 18:08:59.812 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-17 18:08:59.831 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-17 18:08:59.831 INFO    gensim.models.base_any2vec: EPOCH - 3 : training on 162653 raw words (139452 effective words) took 0.4s, 371942 effective words/s\n",
      "2021-05-17 18:09:00.213 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-17 18:09:00.248 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-17 18:09:00.250 INFO    gensim.models.base_any2vec: EPOCH - 4 : training on 162653 raw words (139121 effective words) took 0.4s, 344743 effective words/s\n",
      "2021-05-17 18:09:00.626 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 1 more threads\n",
      "2021-05-17 18:09:00.645 INFO    gensim.models.base_any2vec: worker thread finished; awaiting finish of 0 more threads\n",
      "2021-05-17 18:09:00.646 INFO    gensim.models.base_any2vec: EPOCH - 5 : training on 162653 raw words (139274 effective words) took 0.4s, 354288 effective words/s\n",
      "2021-05-17 18:09:00.647 INFO    gensim.models.base_any2vec: training on a 813265 raw words (696473 effective words) took 1.9s, 364706 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word to vector core training complete\n",
      "LDA core training complete\n",
      "\u001b[K--engine retrained--\r"
     ]
    }
   ],
   "source": [
    "test_engine.addContent('.\\data\\Minutes_02.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "takes -0.41796207427978516 second to load\n"
     ]
    }
   ],
   "source": [
    "check_engine = loadEngine('nlp_engine.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1648, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_engine.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_text = test_engine.df.iloc[0]['content']\n",
    "\n",
    "keywords = ['covid','action','home']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = test_engine.df.iloc[0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanSticker(cleanText,text):\n",
    "    text = text.replace(cleanText,'')\n",
    "    if cleanText in text:\n",
    "        cleanSticker(cleanText,text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stick = cleanSticker('\\n\\n',test_str).replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...\n",
       "subID                                                          0\n",
       "mainID                                                         0\n",
       "filename                                          Minutes_01.pdf\n",
       "date                                         2020-01-07 00:00:00\n",
       "hasDollar                                                  False\n",
       "hasItem                                                     True\n",
       "hasSection                                                 False\n",
       "subID_count                                                   25\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_engine.df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ceff3e1edb9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessy_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspacy_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_c\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLDA_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msynonyms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetSimilar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mretrainStatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\40 Projects\\AWS Hackathon\\stickers\\engine.py\u001b[0m in \u001b[0;36mLDA_init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mtopic_matrix_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'topic_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mtopic_matrix_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"topic\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopic_matrix_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mcontent_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_subID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopic_matrix_df\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0mword2topic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLDA_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'topic_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheng\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheng\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    514\u001b[0m                     \u001b[0mobj_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                         \u001b[0mindexers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sheng\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3171\u001b[1;33m             raise InvalidIndexError(\n\u001b[0m\u001b[0;32m   3172\u001b[0m                 \u001b[1;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3173\u001b[0m             )\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "text = test_engine.clean_text(messy_text)\n",
    "tokens = test_engine.spacy_tokenizer(text)\n",
    "df_c,df_w = test_engine.LDA_init()\n",
    "synonyms = test_engine.getSimilar(keywords)\n",
    "retrainStatus = test_engine.retrain()\n",
    "pageNo = test_engine.getPageCount()\n",
    "wordNo = test_engine.getWordCount()\n",
    "originalText = test_engine.getOriginal('Minutes_01.pdf')\n",
    "notes,topics,keylist = test_engine.searchKeywords(keywords,datetime(2020,1,25),datetime(2020,5,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subID</th>\n",
       "      <th>mainID</th>\n",
       "      <th>filename</th>\n",
       "      <th>date</th>\n",
       "      <th>hasDollar</th>\n",
       "      <th>hasItem</th>\n",
       "      <th>hasSection</th>\n",
       "      <th>subID_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Minutes_01.pdf</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. CEREMONIAL ITEMSNone provided.\\n\\nCity of S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Minutes_01.pdf</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2. CONSENT CALENDAR\\nUpon motion by Councilmem...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Minutes_01.pdf</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1 Approval of City Council Minutes.None prov...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Minutes_01.pdf</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.2 Final Adoption of Ordinances.20-056 Final ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Minutes_01.pdf</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9. REDEVELOPMENT – SUCCESSOR AGENCY  \\n\\n • Op...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>.\\data\\Minutes_02.pdf</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10. LAND USE  \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>.\\data\\Minutes_02.pdf</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.1 Land Use on Consent Calendar  \\n\\n None p...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>.\\data\\Minutes_02.pdf</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.2 20-055 H18 038   Site Development Permit ...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>.\\data\\Minutes_02.pdf</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10.3 20-049 GP18 014, GPT19 004, PDC18 037, PD...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>.\\data\\Minutes_02.pdf</td>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1692 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content subID mainID  \\\n",
       "0   \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n...     0      0   \n",
       "1   1. CEREMONIAL ITEMSNone provided.\\n\\nCity of S...     0      1   \n",
       "2   2. CONSENT CALENDAR\\nUpon motion by Councilmem...     0      2   \n",
       "3   2.1 Approval of City Council Minutes.None prov...     1      2   \n",
       "4   2.2 Final Adoption of Ordinances.20-056 Final ...     2      2   \n",
       "..                                                ...   ...    ...   \n",
       "39  9. REDEVELOPMENT – SUCCESSOR AGENCY  \\n\\n • Op...     0      9   \n",
       "40                                   10. LAND USE  \\n     0     10   \n",
       "41  10.1 Land Use on Consent Calendar  \\n\\n None p...     1     10   \n",
       "42  10.2 20-055 H18 038   Site Development Permit ...     2     10   \n",
       "43  10.3 20-049 GP18 014, GPT19 004, PDC18 037, PD...     3     10   \n",
       "\n",
       "                 filename       date  hasDollar hasItem hasSection  \\\n",
       "0          Minutes_01.pdf 2020-01-07      False    True      False   \n",
       "1          Minutes_01.pdf 2020-01-07      False   False      False   \n",
       "2          Minutes_01.pdf 2020-01-07      False   False      False   \n",
       "3          Minutes_01.pdf 2020-01-07      False   False      False   \n",
       "4          Minutes_01.pdf 2020-01-07      False   False       True   \n",
       "..                    ...        ...        ...     ...        ...   \n",
       "39  .\\data\\Minutes_02.pdf 2020-01-14      False     NaN        NaN   \n",
       "40  .\\data\\Minutes_02.pdf 2020-01-14      False     NaN        NaN   \n",
       "41  .\\data\\Minutes_02.pdf 2020-01-14      False     NaN        NaN   \n",
       "42  .\\data\\Minutes_02.pdf 2020-01-14      False     NaN        NaN   \n",
       "43  .\\data\\Minutes_02.pdf 2020-01-14      False     NaN        NaN   \n",
       "\n",
       "    subID_count  \n",
       "0            25  \n",
       "1            25  \n",
       "2            25  \n",
       "3            25  \n",
       "4            25  \n",
       "..          ...  \n",
       "39           44  \n",
       "40           44  \n",
       "41           44  \n",
       "42           44  \n",
       "43           44  \n",
       "\n",
       "[1692 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_engine.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(pageNo) == type(1)\n",
    "assert type(wordNo) == type(1)\n",
    "assert type(originalText) == type('')\n",
    "assert type(notes)==type(pd.DataFrame())\n",
    "assert type(topics)== type([])\n",
    "assert type(keylist) ==type([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
